% !Mode:: "TeX:UTF-8"

\chapter{代码中间表示与质量评估度量提取}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{引言}

\section{基于clang的抽象语法树生成方法}
抽象语法树（Abstracted Syntax Tree，AST）是一种用来表现编程语言构造的树状
结构，它把代码的语法结构以树形的方式进行了抽象化描述。在这个树形结构中，每一
个节点都对应着代码中的某个元素，比如变量声明、语句或者是表达式等。从这棵树的
根节点出发，代码逐步被拆解成更小的部分，直到最终到达叶节点，这些叶节点代表了
代码中最基本的元素，如操作符或变量等。在这棵树中，节点之间的连接仅表明了它们
之间的层级关系，即父节点与子节点的关系。通过这样的结构，AST 能够清晰地展示出
代码的层次和结构，为编译器或其他工具分析和处理代码提供便利。


Clang 是由苹果公司发起的支持 C、C++、Objective-C 和 Objective-C++语言的编译
器前端，负责对代码进行词法分析、语法分析和语义分析，对程序代码的分析和理解至
关重要[7]。词法分析通过识别 Token 将程序代码分解成基本单元。语法分析在此基础上
识别程序的语法结构，构造抽象语法树。语义分析消除语义模糊，生成属性信息，让计
算机生成目标代码。而libclang 是 Clang 编译器的一个重要组成部分，它提供了一套用于解
析源代码的程序接口。这些程序接口允许开发者在项目中使用 Clang 的强大语言
解析和代码分析功能[8]。本文使用了libclang 生成
AST ，提取代码中的调用和依赖关系，为后续进一步分析提供基础。


这里通过一个简单的例子来说明libclang的使用方式。如图 2-1 所示，这里定义了一个简单的 C 语言文件，文件中声明并定义了
了两个函数和一个全局变量，主函数用于计算两个数的和。
\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{代码示例}
\caption{示例代码}
\end{figure}
这段代码由 Clang 解析生成抽象语法树后，得到的树结构如下图 2-2 所示。
\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{ast示例}
\caption{示例代码对应的抽象语法树结构}
\end{figure}

在 libclang 解析得到的抽象语法树中，游标（cursor）是一个核心概念，它作为一个
指针或引用存在，每个 cursor 都与 AST 中的一个特定节点相对应，表示了源代码中的
一个结构元素。通过操作 cursor，可以遍历整个 AST，访问和分析代码中的各种元素，
如获取变量的类型、函数的参数列表、类的成员等。libclang 提供了一系列 API 函数来
操作 cursor，例如：遍历 AST 中的 cursor、获取 cursor 的类型（如是否为方法定义、变
量定义、变量引用等）、获取 cursor 所代表的源代码元素的名称、类型、位置等信息、
获取 cursor 的父节点或子节点等。本文通过操作游标，遍历 AST，获取整个 AST
的结构。


Clang 定义了一套节点类型标识。AST 的顶层节点类型是Translation\_Unit标签，表
示一个翻译单元，对 AST 树的遍历，实际上就是遍历整个 Translation\_Unit。Function\_Decl
指的是函数定义，在 clang 中是不区分函数声明和函数定义的，统一用 Function\_Decl
来标识，两个区分主要看是否有函数体，在 libclang 中提供了程序接口供开发者调用判断。
Parm\_Decl 是参数节点，上面的例子中，函数 addNumbers 有两个参数 a 和 b。
CompoundStmt 代表大括号，函数实现、struct、enum、for 的 body 等一般用此标签包起
来。DeclStmt 是定义语句，里边可能有 VarDecl 等类型的定义，VarDecl 是对变量的定
义。CallExpr 标签表示函数调用 Expr，子节点有调用的参数列表。ReturnStmt 表示返回
语句。






\section{方法调用链提取与分析}
本文以整个代码项目为分析对象，代码中的方法为分析单元，方法之间的调用关系则是本文的分析基础。在使用 libclang 提取代码的抽象语法树后，遍历整棵树来提取方法之间的调用关系。这部分我们重点关注抽象语法树上的方法节点，以及方法节点内部的调用节点，对应着代码中，方法的定义和方法内部对其他方法的调用。


对抽象语法树的遍历主要分为两次，第一次遍历的目的是获取所有的方法定义。首先提取所有的
FUNCTION\_DECL 节点，它表示方法的定义，在该节点中可提取方法签名。在
FUNCTION\_DECL 节点下，提取子节点 PARM\_DECL，该节点表示方法的参数列表，
在该节点中可提取参数名称和参数类型等参数相关信息。然后提取 FUNCTION\_DECL
节点的子节点 VarDecl，该节点表示在该方法内定义的局部变量。在对方法进行分析时，
我们本身不关心方法的内部实现，但是由于在 C/c++语言中，存在局部变量可以和全局
变量重名的情况，在这里提取方法内定义的局部变量，方便后续在提取全局变量时，对
变量进行作用域的判断。除此之外，还需提取整个方法的 token 序列，所在文件以及作
用域。


第二次遍历的目的是提取方法之间的调用关系。提取 FUNCTION\_DECL 节点
的子节点 CALL\_EXPR，该节点标签表示的是调用语句，可提取调用的方法名。注意，
由于主要分析该项目中由开发者定义的方法之间的依赖关系，所以对于一些标准库方法
的调用选择忽略，不进行提取。具体的计算流程如算法 2-1 所示。


\begin{algorithm}[H]
    \caption{Scan and Analyze Code Files}
    \KwIn{项目中的所有代码文件: $files$}
    \KwOut{方法摘要表: $functions$}
    \KwLine
    \SetKwFunction{FMain}{scanAndAnalyze}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$files$}}{
        $functions \gets \{\}$ \KwComment{$\#$ 初始化方法摘要} \;
        \KwLine
        \KwComment{$\#$ 第一次扫描：收集方法的定义} \;
        \ForEach{$file \in files$}{
            $cursor \gets \text{libclang.parse}(file).cursor$ \KwComment{$\#$ 获取AST的根cursor} \;
            \texttt{traverse(cursor, 0, functions, file, True)} \KwComment{$\#$ 遍历AST，收集方法定义} \;
        }
        \KwLine
        \KwComment{$\#$ 第二次扫描：分析方法调用情况} \;
        \ForEach{$file \in files$}{
            $cursor \gets \text{libclang.parse}(file).cursor$ \KwComment{$\#$ 获取AST的根cursor} \;
            \texttt{traverse(cursor, 0, functions, file, False)} \KwComment{$\#$ 分析方法调用} \;
        }
        \KwLine
        \KwReturn{return $functions$} \;
    }
    \KwLine
    \SetKwFunction{FTraverse}{traverse}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FTraverse{$node, depth, functions, filePath, isFirstScan$}}{
        \If{$isFirstScan$}{
            \If{$node.kind == CursorKind.FUNCTION\_DECL$}{
                $function \gets \text{collectionInfo}(node)$ \KwComment{$\#$ C收集方法信息} \;
                $functions.\text{add}(function)$ \KwComment{$\#$ 将方法添加到方法摘要} \;
            }
        }
        \ElseIf{$node.kind == CursorKind.CALL\_EXPR$}{
            \texttt{parse(node)} \KwComment{$\#$ 分析被调用的函数} \;
        }
        \ForEach{$n \in node.get\_children()$}{
            \texttt{traverse(n, depth + 1, functions, filePath, isFirstScan)} \KwComment{$\#$ 递归遍历子节点} \;
        }
    }
    \end{algorithm}

\clearpage
分析结束后，将会获得每个方法的方法调用链，对应于一个方法摘要表，包括项目
代码中所有的方法和方法之间的调用关系，除此之外还包括方法的参数表、方法主体和
所在文件等其他信息。

\section{全局变量定义-使用链提取与分析}
在C/c++代码中，全局变量的定义、作用域、生命周期和方法是类似的，所以在本文中，将全局变量也作为独立的代码单元进行分析。
全局变量定义-引用链的提取和方法的定义和调用提取类似,对 AST 的遍历主
要也分为两次。具体流程如图2-3。

\begin{figure}[h]
\centering
\includegraphics[width = 0.7\textwidth]{全局变量提取流程图}
\caption{示例代码对应的抽象语法树结构}
\end{figure}

第一次遍历获取所有的全局定义。首先提取所有的
VAR\_DECL 节点，它表示变量定义，然后提取节点中的变量名和变量类型。注
意,由于在 AST 中的节点标签中无法区分变量是否是全局的，所以这里根据节点在 AST
中的深度来判断是否是全局变量，并且在变量名前加上针对该项目文件的绝对路径，来
保证变量名的唯一性。在确定其为全局变量后，还需进一步提取该变量的作用域。在
C/c++语言中，static关键字可用于修饰变量和方法，意味着该变量或该方法只能在其所在文
件内使用，而不是全局可用，因此需要对其作用域进行判断。一次遍历提取到的结果是
一个全局变量表，这里使用哈希表 Map<Name, globalVar>的数据结构进行存储，方便对
全局变量进行查找。

第二次遍历的主要目的是提取全局变量的引用点。在方法节点子树中搜索
DECL\_REF\_EXPR 节点，该类型节点表示对变量的引用，这里首先判断被引用的变量是否是局部
变量，根据方法摘要表中该方法的相关信息可以判断，如果是则直接返回，因为我们不关心方法内的局部变量引用。如果不是，则证
明使用的是全局变量，首先在哈希表中进行查找该变量名，以节省检索时长，如果查找到了，说明
是在该文件中定义的全局变量，同时能够保证被 static 修饰的全局变
量的判断的准确性。如果没有查找到，则说明引用了别的文件中定义的全局函数，则在哈希
表中进行遍历查找，记录该全局变量被引用的方法。具体提取流程如图 2-3 所示。

分析结束后，则获得了每个全局变量的定义-引用链，对应于一个全局变量信息表，
包括项目代码中所有的全局变量和变量的引用点，除此之外还包括全局变量的类型、作
用域和所在文件等其他信息。

\section{基于方法特征的代码度量提取}

代码内聚度和代码耦合性是衡量软件设计质量的两个核心指标，它们直接反映了代
码质量。代码内聚度指的是模块（如函数、类或组件）内部元素之间的相关性。高内聚
度意味着模块内的所有元素都紧密地围绕着一个单一的、明确的功能，代码更容易理解
和维护[9]。代码的耦合性则描述了模块之间的相互依赖。低耦合度意味着模块之间的依
赖关系最小化，每个模块都可以独立地执行其功能，而不需要过多地依赖其他模块。低
耦合度的代码更容易测试和维护[10]。


基于方法摘要和全局变量信息表，我们计算如下代码度量，用于分析代码质量。


\subsection{基于内聚度缺乏度的内聚性分析}

LCOM（Lack of Cohesion in Methods）系列指标是根据模块内聚度的缺乏程度来衡量模块的内聚度的指标。在本文中，
面向对象语言以类为研究范围进行计算内聚度，非面向对象的语言以文件为研究范围进
行计算，类中的成员属性对应文件中的全局变量，类中的成员方法对应文件中定义的方
法。LCOM 指标的核心思想是度量一个类中方法对实例变量（属性）的共享程度。不同
版本的 LCOM 有着不同的计算方法和含义，体现了不同的侧重点。这里一共计算以下四个指标：


（1）LCOM1，含义是不引用相同字段的方法对数目[11]。计算公式如式(2-1)
\begin{equation}
    {LCOM1}=\left\{
        \begin{array}
        {c}P-Q,  ifP\geq Q \\
        0,  otherwise
        \end{array}\right.
\end{equation}

其中，P 是不共享实例变量的方法对的数量，Q 是共享实例变量的方法对的数量。
如果 LCOM1 的结果为负数，则被置为 0。
在计算时，对于每个文件首先构建方法耦合图（method coupling graph），将提取到
的方法作为图中节点，对方法两两进行判断，如果两个节点都引用相同的字段，则它们
之间用一条无向边连接，按式(2-2)计算，
\begin{equation}
LCOM1 = choose(n,2)-e
\end{equation}

其中 n 是文件中的方法总数，e 是图中的实
际边数，即图中可能的最大边数减去实际的边数，得到的值即为 LCOM1

（2）LCOM2，含义是不引用相同字段方法对与引用相同字段方法对数之差[12]。
LCOM2相比于LCOM1，考虑到了类中所有方法和变量的相互作用，其计算公式如式2-3：
\begin{equation}
{LCOM2}=\frac{1}{{a}}{\sum(a-m_{a})}
\end{equation}
其中，\(a\)是类中属性的数量，\( m_a \)是访问属性\(a\)的方法数量。
在计算时，首先构建方法属性图（method-attribute graph），将提取到的方法和全局
变量作为图中节点。如果方法引用了变量，则有一条有向边从方法节点指向属性变量，
计算公式如式2-4，
\begin{equation}
{LCOM2} = 1 - \frac{e}{n \times a}
\end{equation}
其中 \(n\) 为方法数，\(a\) 为变量数。假设 \(e\) 是图中的实际边数，得到的值即为 LCOM2。

（3）LCOM3，含义是以方法为顶点，两方法引用相同字段则有边构成的无向图的连通
分支数[12]。
LCOM3 是对 LCOM2 的进一步改进，其计算公式如式2-5：
\begin{equation}
{LCOM3=(\frac{\sum_{i=1}^n(m_i-a_i)}{m})-a}
\end{equation}
其中，\(m\)是方法的数量，\(a\)是变量的数量，\( m_i \)是第 i 个方法访问的属性数
量，\( a_i \)是被第 i 个方法访问的属性数量。LCOM3 试图通过分析方法和属性之间的关系
来提供更细致的内聚度度量。

实际计算时，如式2-6，基于上述计算出的 LCOM2 指标可以快速地计算出 LCOM3
\begin{equation}
{LCOM3} & = & \frac{n}{n-1} \times {LCOM2}  & = & \frac{n - \frac{e}{a}}{n-1}
\end{equation}

（4）LCOM4，含义是以方法为顶点，两方法引用相同字段或有调用关系则有边构成无
向图的连通分支数[13]。

计算时，构建方法耦合图，节点是方法。如果两个节点都引用相同的字段，则它们
之间用一条无向边连接，除此之外，如果两个节点有调用关系，则也用一条无向边将它
们连接。根据深度搜索的方式，计算图中的连通分支数，得到的值即为LOCM4.

\subsection{基于连通性的内聚性分析}
TCC（Tight Class Cohesion）和 LCC（Loose Class Cohesion）是用于衡量模块内
聚度的指标，这两个指标主要关注于模块中方法之间的连通关系，核心思想是通过
分析模块中方法如何相互作用以及如何访问共同资源（如全局变量）来评估模块的内聚度。


（1）TCC，含义是有连通关系的方法对数与总方法对数的比值[14]。
TCC 关注于模块中方法之间的“直接连接”。如果两个方法直接共享访问同一个变
量，则认为这两个方法是直接连接的。计算时，对于每个文件首先构建方法耦合图，对
方法两两进行判断，如果两个节点都引用相同的字段，则它们之间用一条无向边连接，
计算公式如式2-7，其中\(n\)是文件中的方法总数，\(e\)是图中的实际边数
\begin{equation}
{TCC} = \frac{e}{choose(n,2)}
\end{equation}

（2）LCC，基于方法间接引用共同字段关系的传递闭包计算[14]。
LCC 除了考虑直接连接的方法对外，还包括了间接连接的方法对。如果两个方法不
是直接连接，但可以通过一系列的方法调用来连接，则认为它们是间接连接的。LCC 的
值基于模块中直接或间接连接的方法对占所有可能方法对的比例来计算。因此，LCC 的值
通常不低于 TCC 的值，并且提供了一个更宽泛的模块内聚度视角。


计算时，对于每个模块首先构建方法耦合图，对方法两两进行判断，如果两个节点
都引用相同的字段，则它们之间用一条无向边连接表示直接连接，如果方法之间有调用，
则也将方法进行连接，并连接当前节点和调用节点的所有邻居节点。计算公式如式 2-8，

\begin{equation}
{LCC=e+\frac{e_{indirect}}{choose(n,2)}}
\end{equation}
其中\(n\)是文件中的方法总数，\(e\)是图中的直接连接边，\(e_{indirect}\)是除直接连接边的边数。


\subsection{方法间耦合性分析}

耦合是在软件架构中用来描述模块间相互依赖和连接程度的一个重要指标。耦合度的高低直接影响到系统的维护性和可扩展性。在现有的研究和实践中，耦合度通常被细分为六个等级，这些等级从高到低反映了模块间依赖的紧密程度。本文关注的是方法与方法之间的耦合性，方法间的耦合性反映了不同方法之间的依赖关系，它直接影响代码的可读性、可测试性以及后续的维护和扩展。通过深入分析方法级别的耦合性，研究方法如何通过参数传递、调用关系、共享全局变量等方式相互依赖，我们可以更准确地识别潜在的设计缺陷和优化机会，从而提高系统的模块化程度，增强系统的可维护性和可扩展性。

\begin{table}[htbp]
\caption{软件架构中耦合性分类}
\vspace{0.5em}\centering\wuhao
\begin{tabular}{ccccc}
\toprule
耦合性类别 & 描述 & 耦合程度 & 本文是否分析 \\
\midrule
内容耦合 & 模块直接访问或修改另一个模块的内部数据 & 6 & 否\\
公共耦合 & 模块访问同一公共数据环境 & 6 & 是 \\
外部耦合 & 模块共享全局简单数据结构 & 4 & 是 \\
控制耦合 & 模块传递控制信息，影响计算流程 & 3 & 是 \\
标记耦合 & 通过参数传递复杂数据结构信息 & 2 & 是 \\
数据耦合 & 通过参数传递简单数据 & 1 & 是 \\
\bottomrule
\end{tabular}
\end{table}


内容耦合是耦合度最高的一种形式，它表示一个模块能够直接访问或修改另一个模块的内部数据和结构。在方法级的耦合分析中，这种耦合形式通常不被考虑，因为方法间的直接数据访问往往通过参数传递或者 API 调用实现，而不是直接的内容访问。

公共耦合发生在多个模块共同访问某个全局数据环境时。这种数据环境可能是全局数据结构、全局变量或内存公共区域等。在提取到的全局变量表中，对于复杂数据结构如结构体和数组，其引用点所在的方法之间均存在公共耦合关系。


外部耦合与公共耦合相似，但区别在于它涉及的是对全局简单变量的访问。例如，当多个模块访问或修改相同的全局简单类型变量时，则这些模块之间存在外部耦合。


控制耦合指模块之间传递信息中包含用于控制模块内部的信息。在提取到的方法摘
要表中，遍历方法，如果该方法调用其他方法时，对应方法的参数列表中有变量决定了
被调用方法中的计算流程，则方法之间存在控制耦合关系。


标记耦合指通过参数表传递数据结构信息，调用时传递的是数据结构。在方法摘要
表中提取了方法的参数列表，包括参数名和参数类型，根据参数类型，可以确定
参数表中是否包含复杂类型。除此之外，在方法的调用表中，也提取了方法调用的
函数，结合这两个信息，即可确定两个方法是否存在着标记耦合关系。


数据耦合指通过参数表传递简单数据。与标记耦合类似，根据参数类型可以确定参
数是否全部为基本类型，结合方法调用表，即可确定两个方法是否存在数据耦合。
\subsection{方法扇入扇出度量分析}

方法的扇入（Fan-in）和扇出（Fan-out）是软件工程中用于衡量方法复杂性和模块
间依赖关系的两个指标。


扇入是指调用某个方法的不同方法的数量。它表示了一个方法对其他方法的依赖程
度。扇入值较高的方法通常被认为是重要的或核心的，因为它们被多个其他方法所依赖。
高扇入值可能意味着该函数执行了一个基础或共享的任务。


扇出是指某个方法直接调用的不同方法的数量。它表示了一个方法对其他方法的影
响程度。扇出值较高的方法可能更复杂，因为它们需要管理和协调更多的方法调用。高
扇出值可能意味着该方法具有较高的责任度，且可能更难以理解和维护。

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\textwidth]{扇入扇出.png}
\caption{扇入扇出示例图}
\end{figure}

本文中对于提取到的方法摘要表，遍历每一个方法，统计其调用方法的数量即可计算出该
方法的扇出值，再以该方法名在方法摘要表中搜索调用了该方法的方法，统计总数，得
到的值即为扇入值。

\section{实验结果与分析}

\subsection{实验数据描述与分析}
本文收集了表2-2中所示的软件项目为示例项目，这些项目在github上的收藏数均在千以上，说明这些项目在开源社区中有着一定的影响力，使用范围比较广泛。除此之外，这些项目有着比较活跃的社区，说明其还在不断更新迭代过程中，所以能提供较为丰富的变更历史，以供后续的实验分析。

\begin{table}[htbp]
\caption{示例项目}
\vspace{0.5em}\centering\wuhao
\begin{tabular}{cp{10cm}c}
\toprule
项目名称 & 项目简介 & 收藏数 \\
\midrule
antiword & 用于提取 Microsoft Word 文档内容的工具 & 13k\\
librdkafka & Apache Kafka 的 C/C++ 客户端库，用于与 Kafka 集群
进行通信 & 18k \\
TheAlgorithms & 各种算法的开源实现的集合，涵盖了计算机科学、数学和统计学、数据科学、机器学习、工程等各种主题 & 57k \\
libbpf & linux 内核观测技术的一个脚手架库 & 1.9k \\
FFmpegKit & FFmpeg 工具包 & 3.7k \\
jemalloc & 通用的 malloc(3)实现，强调碎片避免和可扩展的并发支
持 & 9k \\
\bottomrule
\end{tabular}
\end{table}

对示例项目提取基于内聚度缺乏度和基于连通性的内聚度指标、耦合性以及扇入扇出，这些指标一定程度上反映了代码质量。内聚度在本文中是一个模块级别的指标，它衡量一个模块内部各个组件（本文中是方法和全局变量）之间关系的紧密程度的指标。内聚度高的模块意味着模块内的各个部分紧密合作以完成某一特定任务，模块的职责单一，功能聚焦。本文中计算了两类共六种内聚度指标，在同一项目中，人工检查每种内聚度在最差的前5\%的模块，判断是否能被开发者接受，以此来验证内聚度指标的有效性。

对于耦合性，本文中提取了五种不同的耦合类别，每种类别的耦合程度并不相同，数据耦合、标记耦合、外部耦合、公共耦合，耦合程度依次递增。这里对于耦合性的判别标准需要根据是否在同一个模块进行区分。对于同一模块内，代码往往有共同的上下文和职责范围，因此要求尽量采用数据耦合，因为通过参数传递数据，方法的输入输出明确，易于测试和维护；允许标记耦合和外部耦合，允许通过传递数据结构优化参数列表简洁性；减少公共耦合，模块内共享状态可提高效率，但要避免复杂的依赖关系。对于不同模块的方法，则要求尽量采用数据耦合，数据耦合方法之间的独立性强，模块职责单一，代码易于测试和复用；减少标记耦合，优化接口设计，避免通过标记变量传递复杂的变量；杜绝公共耦合、外部耦合：避免全局变量的滥用，防止影响模块之间的依赖关系和模块内部的可测试性。同样也是通过人工检验不符合要求的耦合性，判断是否能被开发者接受，以此来验证耦合性指标的有效性。

对于扇入扇出也是类似的，传统要求尽量高扇入低扇出，高扇入表示其他模块依赖该模块，模块的功能可能是系统中其他模块的核心或基础，复用性较好；低扇出表示该模块没有过多地依赖其他模块，因此它具有更高的独立性，更易维护。这里也是通过人工检查两种指标在最差的前5\%的方法，判断是否能被开发者接受，以此来验证扇入扇出指标的有效性。

接受率指标计算公式如式2-9
\begin{equation}
{AR} = \frac{A}{T} \times 100\%
\end{equation}
其中AR表示接受率，A表示开发者接受的不符要求的示例数，T表示方法检测到的不符要求的样例数。




\subsection{实验结果与分析}
（1）内聚度接受率实验结果及分析

对示例项目人工检验得到的接受率进行统计，得到的结果如表2-3。

\begin{table}[htbp]
\caption{内聚度接受率}
\vspace{0.5em}\centering\wuhao
\begin{tabular}{ccccccc}
\toprule
项目名称 & LCOM1 & LCOM2 & LCOM3 & LCOM4 & TCC & LCC \\
\midrule
antiword & 91.3 & 84.2 & 84.2 & 91.3 & 84.2 & 84.2 \\
librdkafka & 73.7 & 73.7 & 73.7 & 73.7 & 78.4 & 78.4 \\
TheAlgorithms & 89.2 & 74.9 & 74.9 & 89.2 & 74.9 & 74.9 \\
libbpf & 87.3 & 83.4 & 87.3 & 87.3 & 93.7 &  93.7 \\
FFmpegKit & 71.3 & 69.2 & 74.9 & 76.6 & 89.3 & 84.9 \\
jemalloc & 82.2 & 82.2 & 82.2 & 82.2 & 88.6 & 88.6 \\
\bottomrule
\end{tabular}
\end{table}
对于内聚度的接受率，经过分析可以发现指标基本都在70\%以上，表现良好。通过对比，发现在antiword、TheAlgorithms等比较简单的项目中，内聚度在6项指标中常出现相同的接受率，经过分析发现这是因为在同一项目中，尽管6项指标的计算方式和侧重点都不同，但是最差的前5\%基本上是重合的，这意味着一个模块如果在LCOM1中表现的很差，在其他指标中也通常表现得很差，这符合通常认知，同时也侧面验证了指标的准确性。但是对于FFmpegKit等较复杂的项目，6项指标则不太相同，体现了不同内聚度计算方式的侧重点。

（2）其他度量接受率实验结果及分析

对示例项目人工检验得到的接受率进行统计，得到的结果如表2-4。

\begin{table}[htbp]
\caption{示例项目}
\vspace{0.5em}\centering\wuhao
\begin{tabular}{cccc}
\toprule
项目名称 & 耦合性AR & 扇入扇出AR & 静态工具缺陷AR \\
\midrule
antiword & 84.2 & 56.4 & 100.0 \\
librdkafka & 73.7 & 43.3 & 98.8 \\
TheAlgorithms & 99.2 & 87.6 & 100.0 \\
libbpf & 78.3 & 42.1 & 100.0 \\
FFmpegKit & 64.0 & 43.3 & 94.6 \\
jemalloc & 87.8 & 43.3 & 100.0 \\
\bottomrule
\end{tabular}
\end{table}

首先分析耦合性，耦合性的接受率在几个项目中的表现不尽相同。对于结构较为简单的项目，如antiword和jemalloc，接受率均能达到较高的水平，在TheAlgorithms项目上甚至能达到99\%以上的接受率，这是因为简单项目结构较为简单，各个模块功能明确，职责单一，所以耦合性不达标准的情况很容易被检测和接受，维护起来也更加容易，尤其对于TheAlgorithms，这个项目是对各种算法的开源实现，模块和模块之间几乎不存在相互依赖和调用的情况，每种算法独立开发，更像是库函数，仅在需要时供开发者调用，所以耦合性过高的样例很少，而且也更容易被接受。而在复杂项目中，如FFmpegKit，耦合性接受率相较其他项目更低一些，这是由于对与大型、复杂的软件项目来讲，各模块和方法之间的依赖关系可能已经非常复杂，需要大量时间来理解现有结构并分析方法间的相互影响，对于某些功能，也的确缺乏耦合性更低的实现方式，所以接受率更低。

对于扇入扇出值，可以发现在这个指标上的接受率是最低的。经过实例分析，发现大部分的项目的开发模式并不完全符合高扇入低扇出的标准。比如低扇入的模块虽然复用性低，但是更加独立，意味着它们不太依赖于其他模块的实现，因此更容易被单独测试、维护和扩展，考虑到未来软件的发展，这些低扇入的方法也可能被调用，所以不能被直接接受。对于高扇出方法的检测结果，大部分是可以接受的，但是存在某些高扇出的模块实际上是中心化的模块，类似main方法，集中处理功能逻辑能够减少冗余代码，还能减少因为方法调用导致的内存栈增加。

静态工具检验得到的代码缺陷的接受率是最高的，经过分析发现只有个别错误如头文件引用错误、变量未使用等错误等不容易被开发者所接受，因为这并不是代码本身的结构问题。

（3）


\section{本章小结}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{面向代码质量评估的变更影响分析方法研究}
\section{引言}
方法之间的变更影响的类型可以分为以下三种类型：

（1）有直接调用关系
这种变更影响关系是显而易见的。比如方法 funcA 调用了方法 funcB，那么当 funcB
的方法签名有所变化时，调用它的方法必须对应地修改代码才能正常调用，否则会调用
不成功，甚至直接发生编译错误。

（2）共同调用另一个方法
如当 funcA 和 funcC 同时调用了方法 funcB 时，funcA 和 funcC 之间会有变更影响
关系。这种变更影响关系实际上是类型 1 的扩展，这种情况通常是 funcB 的更改引起了
funcA 和 funcC 的同时更改。

（3）逻辑上存在变更影响关系
这种变更影响关系中，方法之间虽然没有直接的调用关系，也不共同调用某个方法，
但它们的实现逻辑或者所操作的数据之间存在某种隐含的关联。这种关系可能是由于它
们共同维护某个数据的一致性、共享某些资源或者它们的输出和输入之间存在某种预期
的联系。因此，当其中一个方法发生变化时，可能会间接影响到其他方法的行为或结果，
即使这种影响在代码的静态结构中不直接可见。

\section{基于依赖关系闭包的变更影响分析}

在代码变更影响关系分析中，依赖关系传递闭包分析是一种用来预测代码变更可能
影响到的其他部分的技术[15]。这种方法依赖于对代码中各个元素之间依赖关系的深入
分析，通过这些依赖关系的传递来识别受影响的代码方法。这种变更影响关系是后续进
行模块化分析的基础。

首先识别直接依赖关系。包括函数调用、变量引用等。此前提取到的方法摘要表和
全局变量信息表已经包含了这种直接依赖关系。接下来将依赖关系表示为一个有向图，
其中节点代表代码中的元素，包括方法、全局变量，有向边代表依赖关系。这个依赖图
是分析代码变更影响的基础。对于依赖图中的每个节点，计算其传递闭包。传递闭包是
指从该节点出发，通过依赖关系可以直接或间接到达的所有节点的集合。这一步骤通过
图深度优先搜索来实现。

对于图中的所有方法节点进行变更影响分析，我们假设该节点有变更，计算传递闭
包后，得到的方法集合即为与当前方法有变更影响关系的方法。

以图 2-5 为例，在这个例子中，一共有 4 个方法，其中方法 funcA 调用了 funcB 和
funcD，funcB 调用了 funcC。在对 funcC 进行变更影响分析时，会直接影响到 funcB，
根据依赖关系闭包，会间接影响到 funcA。所以与 funcC 有变更影响关系的方法集合为
{funcB, funcA}。

\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{依赖关系示例.png}
\caption{依赖关系示例}
\end{figure}

\section{基于代码克隆的变更影响分析}
\subsection{代码分段及代码指纹提取}
\subsection{基于ClaSP算法的代码克隆检测方法}

\section{基于数据挖掘的变更影响分析}
\subsection{代码变更历史提取}
基于依赖关系闭包的方法可以识别方法之间浅层的变更影响关系，主要针对的是语
法和依赖关系层面，而无法抽取更深层的关系，因此设计了基于数据挖掘技术的变更影
响分析方法。本方法主要针对拥有代码变更历史记录的软件项目。其主要理论是认为在
代码变更历史中，频繁出现同时更改的方法对是存在着一定的变更影响关系的。这一过
程可以分为以下几个步骤：

这里为方便分析代码变更历史，主要分析对象为 git 项目。首先是收集项目的代码
库及其变更历史记录。然后，提取项目中的所有提交（commit），每个提交可能包含多
个更改文件。对于标记为“修改”的文件，提取所有变化的代码行，并定位这些代码行在
源代码中的方法，进而提取该方法体。收集每个提交中所有变更的函数，形成一个与该
提交相关的变更函数列表。

\subsection{基于频繁模式挖掘的变更影响关系提取}

接下来，基于数据挖掘中的频繁模式挖掘理论，识别可能存在变更影响关系的函数
对。频繁模式指的是在数据集中经常一起出现的项目或特征组合，而频繁项集是频繁模
式的具体表现形式。频繁项集是指在数据集中经常同时出现的一组项，如果一个项集的
支持度（即该项集出现的记录占总记录数的比例）超过了预先定义的最小支持度阈值，
则认为该项集是频繁的。在分析提交时，针对一个方法 A，记录其在所有提交记录中出
现的次数为 N，而在这些提交中，统计其他出现的方法次数 M，如对方法 B，记录其出
现的次数为 M。如果 M/N 的值为设定的阈值= 1，则认为方法对（A，B）有变更影响
关系。换言之，这意味着每当 A 出现时，B 也必然出现，方法对（A， B）每次更改都
为同时更改。

遍历项目变更历史，抽取出有变更影响关系的方法对，认为它们之间存在着变更
影响关系

对收集到的数据进行分析，这里以真实项目中挖掘到的方法对为例，如图 2-6 中所
示，这个项目是 kafka 的一个 C/c++客户端。方法一的主要功能是在 Kafka 模拟环境中
按照一定的规则生成 Producer ID，而方法二的功能是检查一个 Producer ID 是否有效。
当涉及检查的逻辑时，往往需要考虑到它是如何被创建和分配的。在这个例子中需要确
保 ID 的创建逻辑与检查逻辑一致，才能确保检查是正确的。这个方法中，对于要检查
的 Producer ID，首先会判断事务 ID，然后再检查 epoch，逻辑与创建 ID 是形成对应的。
考虑修改的行为，如果对于 Producer ID 的创建和分配逻辑进行了修改，那么通常需
要同时修改 Producer ID 检查逻辑，以确保两者保持一致。否则，如果创建和分配逻辑
发生了变化，而检查逻辑没有相应地进行调整，就可能导致检查逻辑无法正确地验证新
生成的 Producer ID，从而引入错误和不一致性。

\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{数据挖掘挖到的方法对.png}
\caption{逻辑上有变更影响关系的方法对示例}
\end{figure}


经过分析可以看出，通过数据挖掘方法得到的具有变更关系的方法对，是具有一定
的准确性的，并且可以弥补静态分析的不足。

\section{基于深度学习的变更影响分析}

当项目代码有丰富的变更历史时，可以根据数据挖掘的方式，抽取具有变更影响关
系的方法对，但是当只有项目源代码时，则只能根据静态分析的方式分析。本课题将数
据挖掘得到的数据作为数据集，训练深度学习模型，将模型用于对方法对的变更影响关
系预测，以弥补静态分析方法的不足。

\subsection{数据集的采集与预处理}

根据数据挖掘的变更影响关系分析的方法，可以提取到具有频繁同时更改的方法对，
将这种方法对作为数据集的正例进行收集，然后对方法进行随机取样，作为数据集的负
例收集。

这里我们主要以表 2-1 中的 github 项目为基础收集数据集。选择这几个项目的原因
是它们的收藏数均在千以上，说明这些项目在开源社区中有着一定的影响力，使用比较
广泛。除此之外，这些项目社区比较活跃，还在不断更新迭代过程中，所以能提供较为
丰富的变更历史，以供我们分析。

\subsection{基于codebert的变更影响关系预测}

在进行学习模型的训练时，考虑到对代码的理解性，采用 CodeBERT 作为核心的代
码表示学习模型。首先，将两个方法体分别输入到模型中，通过模型的处理，得到两个
函数体各自的嵌入表示，分别记为 s1 和 s2。接着将这两个向量表示进行拼接，形成合
并后的向量表示。此合并向量随后被送入一个由两层组成的多层感知机（MLP）中进行
进一步的处理。在这个过程中，模型通过学习，尝试捕捉函数体之间的深层次关系。最
终，将模型的输出与真实标签之间做交叉熵损失来进行优化，以此来调整模型的参数，
使模型能够更准确地理解和表示代码之间的关系。

实验结果如表 2-2 所示。实验使用的数据集总共 6000 对左右，按照训练、验证、测
试 集 为 6:2:2 ， 分 别 训 练 了 codebert 系 列 的 两 个 网 络 CodeBERTa-small-v1 和
codebert-base-mlm，具体结果如下：

从总体上来看，两个模型的性能均表现出色，但深入分析召回率（recall）和精确率
（precision）时，可以发现两个模型各有所长。

CodeBERTa-small-v1 模型更加重视精确率，强调预测出的正例的真实性和准确性。
这意味着它在确保预测结果的准确性方面做得很好，但这种方法可能会导致一些正确的
情况被漏掉，即存在漏报的情况。由于"small"模型的规模较小，参数数量较少，这可能
会使得模型在训练过程中更容易发生过拟合现象。

另一方面，CodeBERT-base-mlm 模型更加注重召回率，致力于捕捉尽可能多的正样
本。这种策略虽然能够覆盖更多的正例，但在这个过程中，也可能会引入一些误报，即
将一些实际上是负例的情况错误地判定为正例。大型模型由于具备更强的泛化能力，通
常能够更好地适应新的数据集。因此，为了获得更好的泛化性能，它们通常会牺牲一定
的精确率。

\section{实验结果与分析}

\subsection{实验数据集描述与分析}
\subsection{实验设置}
\subsection{实验结果与分析}

\section{本章小结}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{代码审查图生成}
\section{引言}
对整个项目的分析结果将以代码审查图的方式展示给用户。其中图的节点是代码元
素，包括方法和全局变量，方法和方法以及方法和全局变量之间的关系将以边的形式进
行展示。

\section{基于方法功能标签的方法聚类}
\subsection{基于大语言模型的方法功能标签生成}
\subsection{基于功能标签的方法聚类}

\section{代码审查图}
\subsection{代码审查图构建}
\subsection{代码审查图可视化}

图形可视化方案基于开源项目 G6，构建并展示最终的代码审查图。G6 是一个图形
可视化引擎，它提供了绘制、布局、分析、交互、动画等全方位的图形可视化基础功能。
在图形的节点与边被计算出后，将这些数据以 JSON 格式组织起来，这样可以让 G6 加
载这些远程数据源进行展示，同时也实现了计算逻辑与图形可视化的有效分离。


如图 2-8 所示，目前实现了节点的分类、设置节点属性，以及边的分类、设置边信
息等关键功能。为了提升交互体验，还增加了鼠标悬停时即可查看节点或边信息的便捷
功能。

\section{实验结果与分析}

\subsection{实验数据集描述与分析}
\subsection{实验设置}
\subsection{实验结果与分析}

\section{本章小结}





% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
